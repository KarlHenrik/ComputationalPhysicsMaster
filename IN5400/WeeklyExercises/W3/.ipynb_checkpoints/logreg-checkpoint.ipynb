{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt  # patch-wise similarities, droi images\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen2d_m(mean2, flip, num):\n",
    "\n",
    "    a1 = np.pi*0.0\n",
    "    mat1 = np.array([[np.cos(a1), np.sin(a1)], [-np.sin(a1), np.cos(a1)]])\n",
    "\n",
    "    a2 = np.pi*0.2\n",
    "    mat2 = np.array([[np.cos(a2), np.sin(a2)], [-np.sin(a2), np.cos(a2)]])\n",
    "\n",
    "    z1 = np.random.normal(size=(num//2, 2))\n",
    "    z1[:, 0] = z1[:, 0]*3\n",
    "    x1 = np.dot(z1, mat1)\n",
    "    z2 = np.random.normal(size=(num-num//2, 2))\n",
    "    z2[:, 0] = z2[:, 0]*3\n",
    "    x2 = np.dot(z2, mat2) + mean2.reshape((1, 2))\n",
    "\n",
    "    y1 = (np.random.ranf(size=(num//2)) >=\n",
    "          flip).astype(dtype=np.float32)  # np.ones((num//2))+\n",
    "    y2 = (np.random.ranf(size=(num-num//2)) <=\n",
    "          flip).astype(dtype=np.float32)  # np.zeros((num-num//2,2))\n",
    "\n",
    "    # random label noise in y1, y2\n",
    "\n",
    "    x = np.concatenate((x1, x2), axis=0)  # existing axis\n",
    "    y = np.concatenate((y1, y2), axis=0)  # existing axis\n",
    "\n",
    "    # x.shape=(numdata,dims) dims=2 here\n",
    "    # y.shape=(numdata)\n",
    "\n",
    "    print('means', np.mean(y1), np.mean(y2), np.mean(y))\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    # randomly permute\n",
    "    inds = np.arange(num)\n",
    "    np.random.shuffle(inds)\n",
    "    x = x[inds, :]\n",
    "    y = y[inds]\n",
    "\n",
    "    return x, y  # y is 0 or 1\n",
    "\n",
    "\n",
    "def rndsplit_simple(x, y, numtr):\n",
    "\n",
    "    inds = np.arange(y.size)\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    xtr = x[inds[0:numtr], :]\n",
    "    ytr = y[inds[0:numtr]]\n",
    "\n",
    "    xv = x[inds[numtr:], :]\n",
    "    yv = y[inds[numtr:]]\n",
    "\n",
    "    return xtr, ytr, xv, yv\n",
    "\n",
    "\n",
    "def gendata():\n",
    "    mean2 = np.asarray([1, 3])\n",
    "    flip = 0.1\n",
    "    num = 5000\n",
    "    x, y = datagen2d_m(mean2, flip, num)\n",
    "    numtr = 3000\n",
    "    xtr, ytr, xvt, yvt = rndsplit_simple(x, y, numtr)\n",
    "    xv, yv, xt, yt = rndsplit_simple(xvt, yvt, numtr=1000)\n",
    "\n",
    "    return xtr, ytr, xv, yv, xt, yt\n",
    "\n",
    "\n",
    "def visualize_data(xv, yv, w, bias):\n",
    "\n",
    "    possamples = xv[yv > 0, :]\n",
    "    negsamples = xv[yv <= 0, :]\n",
    "\n",
    "    plt.plot(negsamples[:, 0], negsamples[:, 1], 'bx')\n",
    "    plt.plot(possamples[:, 0], possamples[:, 1], 'rx')\n",
    "\n",
    "    # plot wx+b=0 ... wx= -b, x= a w^O + w/\\|w\\|^2 * -b\n",
    "\n",
    "    def vis1():\n",
    "        a = np.linspace(-10, 10, 200)\n",
    "        worthogonal = np.asarray([-w[1],  w[0]])\n",
    "        normedwtimesbias = -bias * w / np.linalg.norm(w)\n",
    "\n",
    "        points = a * worthogonal / np.linalg.norm(w) + normedwtimesbias\n",
    "        points = points.T\n",
    "        print(points.shape, w.shape)\n",
    "\n",
    "        plt.plot(points[:, 0], points[:, 1], 'c-', linewidth=5)\n",
    "\n",
    "    def vis2():\n",
    "        delta = 0.05\n",
    "        x = np.arange(-10.0, 12.0, delta)\n",
    "        y = np.arange(-10.0, 12.0, delta)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "\n",
    "        U = bias + w[0]*X + w[1]*Y\n",
    "        Z = 1.0/(1.0+np.exp(-U))\n",
    "\n",
    "        CS = plt.contourf(X, Y, Z, levels=8, cmap=cm.viridis)  # coolwarm\n",
    "\n",
    "    vis2()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class logreglayer(nn.Module):\n",
    "    def __init__(self, dims):\n",
    "\n",
    "        super(logreglayer, self).__init__()  # initialize base class\n",
    "\n",
    "        self.bias = torch.nn.Parameter(data=torch.zeros(1), requires_grad=True)\n",
    "        self.w =  # TODO\n",
    "        # YOUR IMPLEMENTATION HERE # shape must be (dims,1), requires_grad to True , random init of values from a zero mean normal distribution\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "\n",
    "\n",
    "def train_epoch(model,  trainloader,  criterion, device, optimizer):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = list()\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # apply gradient to your parameters in model ... model.w and model.bias ... remember about data and grad :)\n",
    "        # TODO\n",
    "        # run it at first using the optimizer, and fill up all other todos,\n",
    "        # then in a second step replace it by your own version which updates the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    gtpos = 0\n",
    "    gtneg = 0\n",
    "    tps = 0\n",
    "    tns = 0\n",
    "    fbeta = 1\n",
    "\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for ctr, data in enumerate(dataloader):\n",
    "\n",
    "            print('epoch at', len(dataloader.dataset), ctr)\n",
    "            inputs = data[0].to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            labels = data[1]\n",
    "            labels = labels.float()\n",
    "            cpuout = outputs.to('cpu')\n",
    "\n",
    "            #_, preds = torch.max(cpuout, 1)\n",
    "            preds = (cpuout >= 0.5).squeeze(1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # this does not work if one uses a datasampler!!!\n",
    "        accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "def train_modelcv(dataloader_cvtrain, dataloader_cvtest,  model,  criterion, optimizer, scheduler, num_epochs, device):\n",
    "\n",
    "    best_measure = 0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train(True)\n",
    "        losses = train_epoch(model,  dataloader_cvtrain,\n",
    "                             criterion,  device, optimizer)\n",
    "        # scheduler.step()\n",
    "\n",
    "        model.train(False)\n",
    "        measure = evaluate(model, dataloader_cvtest, criterion, device)\n",
    "        print(' perfmeasure', measure)\n",
    "\n",
    "        if measure > best_measure:  # higher is better or lower is better?\n",
    "            bestweights = model.state_dict()\n",
    "            best_measure = measure\n",
    "            best_epoch = epoch\n",
    "            print('current best', measure, ' at epoch ', best_epoch)\n",
    "\n",
    "    return best_epoch, best_measure, bestweights\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "    # some parameters\n",
    "    # training batch size\n",
    "    batch_size = 8\n",
    "    # validation batch size\n",
    "    valbatch_size = 32\n",
    "    # number of epochs for training\n",
    "    maxnumepochs = 12\n",
    "    # learning rate\n",
    "    learningrate = 0.01\n",
    "\n",
    "    # define dataset\n",
    "    xtr, ytr, xv, yv, xt, yt = gendata()\n",
    "\n",
    "    # Tensordataset\n",
    "    # TODO\n",
    "    dtr =  # TensorDataset from tensors from xtr, ytr - our training features and labels\n",
    "    dv =  # TensorDataset from tensors from xv, yv - our validation features and labels\n",
    "    # define dataloader over dataset\n",
    "    loadertr = torch.utils.data.DataLoader(\n",
    "        dtr, batch_size=batch_size, shuffle=True)  # returns an iterator\n",
    "    loaderval = torch.utils.data.DataLoader(\n",
    "        dv, batch_size=valbatch_size, shuffle=False)\n",
    "\n",
    "    #model and loss\n",
    "    # TODO\n",
    "    model =  # your logreglayer properly initialized\n",
    "    # TODO\n",
    "    criterion =  # which loss function suits here, given that our model produces 1-dimensional output  and we want to use it for classification?\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=learningrate, momentum=0.0, weight_decay=0)\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    best_epoch, best_perfmeasure, bestweights = train_modelcv(dataloader_cvtrain=loadertr, dataloader_cvtest=loaderval,\n",
    "                                                              model=model,  criterion=criterion, optimizer=optimizer, scheduler=None, num_epochs=maxnumepochs, device=device)\n",
    "\n",
    "    model.load_state_dict(bestweights)\n",
    "\n",
    "    # TODO\n",
    "    dte =  # TensorDataset from tensors from xte, yte - our test features and labels\n",
    "    loaderte = torch.utils.data.DataLoader(\n",
    "        dte, batch_size=valbatch_size, shuffle=False)\n",
    "\n",
    "    test_accuracy = evaluate(\n",
    "        model=model, dataloader=loaderte, criterion=None, device=device)\n",
    "\n",
    "    print('validation accuracy', best_perfmeasure,\n",
    "          'test accuracy', test_accuracy)\n",
    "\n",
    "    visualize_data(xt, yt, model.w.detach(), model.bias.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
