{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emotional-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b2e6de3ad35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m best_all, trainlosses, testlosses, testperfs = traineval2_model_nocv(\n\u001b[1;32m---> 87\u001b[1;33m         dataloaders[\"train\"], dataloaders[\"val\"], model, loss_func, optimizer, lr_sc, num_epochs=config[\"maxnumepochs\"], device=device, numcl=config[\"numcl\"])\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;31m# saving best model and its results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mmodelfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models/bestMdl.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ComputationalPhysicsMaster\\IN5400\\Oblig1\\code\\vocTrainEval.py\u001b[0m in \u001b[0;36mtraineval2_model_nocv\u001b[1;34m(dataloader_train, dataloader_test, model, loss_func, optimizer, scheduler, num_epochs, device, numcl)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mavgloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\ComputationalPhysicsMaster\\IN5400\\Oblig1\\code\\vocTrainEval.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, trainloader, loss_func, device, optimizer)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for training av validation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from vocparseclslabels import PascalVOC\n",
    "\n",
    "from PIL import Image\n",
    "# custom functions\n",
    "from vocTrainEval import dataset_voc, evaluate_meanavgprecision, traineval2_model_nocv, train_epoch\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------- SETUP BLOCK --------------------------\n",
    "config = dict()\n",
    "\n",
    "config[\"use_gpu\"] = True\n",
    "config[\"lr\"] = 0.0005\n",
    "config[\"batchsize_train\"] = 16\n",
    "config[\"batchsize_val\"] = 64\n",
    "config[\"maxnumepochs\"] = 10\n",
    "\n",
    "config[\"scheduler_stepsize\"] = 2\n",
    "config[\"scheduler_factor\"] = 0.3\n",
    "\n",
    "# kind of a dataset property\n",
    "config[\"numcl\"] = 20\n",
    "\n",
    "# data augmentations\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# datasets\n",
    "root_dir = \"VOCdevkit/VOC2012/\"\n",
    "image_datasets = {}\n",
    "image_datasets[\"train\"] = dataset_voc(root_dir = root_dir, trvaltest=0, transform=data_transforms[\"train\"])\n",
    "image_datasets[\"val\"] = dataset_voc(root_dir = root_dir, trvaltest=1, transform=data_transforms[\"val\"])\n",
    "\n",
    "# dataloaders\n",
    "dataloaders = {}\n",
    "dataloaders[\"train\"] = DataLoader(image_datasets[\"train\"], num_workers=0, batch_size = config[\"batchsize_train\"], shuffle=True)\n",
    "dataloaders[\"val\"] = DataLoader(image_datasets[\"val\"], num_workers=0, batch_size = config[\"batchsize_val\"])\n",
    "\n",
    "# device\n",
    "if True == config[\"use_gpu\"]:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "model = models.resnet18(pretrained=True) # pretrained resnet18\n",
    "model.fc = nn.Sequential( # rewriting last layer to have 20 sigmoid outputs\n",
    "    nn.Linear(model.fc.in_features, 20),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = config[\"lr\"])\n",
    "\n",
    "lr_sc = optim.lr_scheduler.StepLR(optimizer, step_size = config[\"scheduler_stepsize\"], gamma = config[\"scheduler_factor\"]) # Decay LR by a factor of 0.3 every X epochs\n",
    "# training\n",
    "best_all, trainlosses, testlosses, testperfs = traineval2_model_nocv(\n",
    "        dataloaders[\"train\"], dataloaders[\"val\"], model, loss_func, optimizer, lr_sc, num_epochs=config[\"maxnumepochs\"], device=device, numcl=config[\"numcl\"])\n",
    "# saving best model and its results\n",
    "modelfile = \"models/bestMdl.pt\"\n",
    "torch.save(best_all, modelfile)\n",
    "print(f\"model saved to {modelfile}\")\n",
    "\n",
    "# Plotting results from training\n",
    "\n",
    "# train and test losses\n",
    "plt.plot(trainlosses, label=\"Train\")\n",
    "plt.plot(testlosses, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Train and test losses\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()\n",
    "# test mAP\n",
    "plt.plot(np.mean(testperfs, axis=1))\n",
    "plt.title(\"Test mAP\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()\n",
    "# tail accuracy\n",
    "def tailAcc(preds, labels, t):\n",
    "    preds_true = np.greater(preds, t) # predicted to be true\n",
    "    correct_pred = np.logical_and(preds_true, labels) # correct predictions!\n",
    "    \n",
    "    return np.sum(correct_pred) / np.sum(preds_true)\n",
    "\n",
    "preds = best_all[\"preds\"].cpu().numpy()\n",
    "labels = best_all[\"labels\"].cpu().numpy()\n",
    "\n",
    "max_t = np.min(np.max(preds, axis = 0)) - 1e-6\n",
    "ts = np.linspace(0, max_t, 20)\n",
    "mean_tail_accs = np.zeros(20) # mean tail acc for each t\n",
    "\n",
    "for i, t in enumerate(ts):\n",
    "    tail_accs = np.zeros(config[\"numcl\"]) # tail accs for each class for this t\n",
    "    for cl in range(config[\"numcl\"]):\n",
    "        tail_accs[cl] = tailAcc(preds[:, cl], labels[:, cl], t)\n",
    "    \n",
    "    mean_tail_accs[i] = np.mean(tail_accs) # mean tail acc for this t\n",
    "\n",
    "plt.plot(ts, mean_tail_accs)\n",
    "plt.title(\"Tailacc averaged over all classes\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-breakdown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
