{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "concrete-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training av validation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from vocparseclslabels import PascalVOC\n",
    "\n",
    "from PIL import Image\n",
    "# custom functions\n",
    "from vocTrainEval import dataset_voc, evaluate_meanavgprecision, traineval2_model_nocv, train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "failing-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change targetmodule to value\n",
    "def setbyname2(targetmodel, name, value):\n",
    "    def iteratset(obj, components, value, nametail=[]):\n",
    "\n",
    "        if not hasattr(obj, components[0]):\n",
    "            return False\n",
    "        elif len(components) == 1:\n",
    "            if not hasattr(obj, components[0]):\n",
    "                print('object has not the component:', components[0])\n",
    "                print('nametail:', nametail)\n",
    "                exit()\n",
    "            setattr(obj, components[0], value)\n",
    "            #print('found!!', components[0])\n",
    "            # exit()\n",
    "            return True\n",
    "        else:\n",
    "            nextobj = getattr(obj, components[0])\n",
    "\n",
    "            newtail = nametail\n",
    "            newtail.append(components[0])\n",
    "            #print('components ',components, nametail, newtail)\n",
    "            # print(type(obj),type(nextobj))\n",
    "\n",
    "            return iteratset(nextobj, components[1:], value, nametail=newtail)\n",
    "\n",
    "    components = name.split('.')\n",
    "    success = iteratset(targetmodel, components, value, nametail=[])\n",
    "    return success\n",
    "\n",
    "# compare outputs of two models\n",
    "def comparetwomodeloutputs(model1, model2, dataloader, device):\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    curcount = 0\n",
    "    avgdiff = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(dataloader):\n",
    "\n",
    "            #if (batch_idx % 100 == 0) and (batch_idx >= 100):\n",
    "            #    print('at val batchindex: ', batch_idx)\n",
    "\n",
    "            inputs = data['image'].to(device)\n",
    "            outputs1 = model1(inputs)\n",
    "            outputs2 = model2(inputs)\n",
    "\n",
    "            diff = torch.mean(torch.abs((outputs1-outputs2).flatten()))\n",
    "\n",
    "            labels = data['label']\n",
    "            #print('diff', diff.item())\n",
    "            avgdiff = avgdiff * (curcount / float(curcount+labels.shape[0])) + diff.item() * (\n",
    "                labels.shape[0] / float(curcount+labels.shape[0]))\n",
    "\n",
    "            curcount += labels.shape[0]\n",
    "\n",
    "    return avgdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "confident-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wsconv2(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, weight, dilation, groups, bias, eps=1e-12):\n",
    "        super(wsconv2, self).__init__(in_channels, out_channels,\n",
    "                                      kernel_size, stride, padding, dilation, groups, bias)\n",
    "\n",
    "        self.weight = weight\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # torch.nn.functional.conv2d documentation tells about weight shapes\n",
    "        n_c = torch.sqrt(torch.var(self.weight, axis = (1, 2, 3)) + self.eps)\n",
    "        scaled = torch.zeros_like(self.weight)\n",
    "        for i in range(len(n_c)):\n",
    "            scaled[i] = self.weight[i] / n_c[i]\n",
    "            \n",
    "        return torch.nn.functional.conv2d(x, weight = scaled, stride = self.stride, padding = self.padding, dilation = self.dilation, groups = self.groups)\n",
    "\n",
    "def bntoWSconverter(model, case):\n",
    "    lastwasconv2 = False\n",
    "    for nm, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            lastwasconv2 = True\n",
    "\n",
    "            usedeps = 1e-12  # use 1e-12 if you add it to a variance term, and 1e-6 if you add it to a standard deviation term\n",
    "            \n",
    "            new_module = wsconv2(module.in_channels, module.out_channels, module.kernel_size, module.stride,\n",
    "                 module.padding, module.weight, module.dilation, module.groups, module.bias, usedeps)\n",
    "            \n",
    "            setbyname2(model, nm, new_module)\n",
    "            n_c = torch.sqrt(torch.var(module.weight.detach(), axis = (1, 2, 3)) + usedeps) # for next batchnorm\n",
    "\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "\n",
    "            if lastwasconv2 == False:\n",
    "                print('got disconnected batchnorm??')\n",
    "                exit()\n",
    "                \n",
    "            if case == \"A\":\n",
    "                module.running_mean /= n_c\n",
    "                module.running_var /= n_c**2\n",
    "            elif case == \"B\":\n",
    "                module.bias = torch.nn.Parameter(module.bias + (module.weight.detach() * n_c - module.weight.detach()) * module.running_mean / (module.running_var + 1e-12)**0.5)\n",
    "                module.weight = torch.nn.Parameter(module.weight * n_c)\n",
    "\n",
    "            lastwasconv2 = False\n",
    "\n",
    "        else:\n",
    "            lastwasconv2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "electrical-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# routine to test that your copied model at evaluation time works as intended\n",
    "\n",
    "config = dict()\n",
    "\n",
    "config['use_gpu'] = True\n",
    "config['lr'] = 0.0005\n",
    "config['batchsize_train'] = 16\n",
    "config['batchsize_val'] = 64\n",
    "config[\"maxnumepochs\"] = 2\n",
    "\n",
    "config[\"scheduler_stepsize\"] = 2\n",
    "config[\"scheduler_factor\"] = 0.3\n",
    "config[\"numcl\"] = 20\n",
    "\n",
    "# data augmentations\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# datasets\n",
    "root_dir = \"VOCdevkit/VOC2012/\"\n",
    "image_datasets = {}\n",
    "image_datasets[\"train\"] = dataset_voc(root_dir = root_dir, trvaltest=0, transform=data_transforms[\"train\"])\n",
    "image_datasets[\"val\"] = dataset_voc(root_dir = root_dir, trvaltest=1, transform=data_transforms[\"val\"])\n",
    "\n",
    "# dataloaders\n",
    "dataloaders = {}\n",
    "dataloaders[\"train\"] = DataLoader(image_datasets[\"train\"], num_workers=0, batch_size = config[\"batchsize_train\"], shuffle=True)\n",
    "dataloaders[\"val\"] = DataLoader(image_datasets[\"val\"], num_workers=0, batch_size = config[\"batchsize_val\"])\n",
    "\n",
    "# device\n",
    "if True == config[\"use_gpu\"]:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Sequential( # rewriting last layer to have 20 sigmoid outputs\n",
    "    nn.Linear(model.fc.in_features, 20),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "based-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model checking averaged difference 0.10155655299211806\n"
     ]
    }
   ],
   "source": [
    "for case in [\"A\", \"B\"]:\n",
    "    model2 = copy.deepcopy(model.to(device))\n",
    "\n",
    "    bntoWSconverter(model2, case = case) # changes model2 inplace\n",
    "    model = model.to(device)\n",
    "    model2 = model2.to(device)\n",
    "\n",
    "    avgdiff = comparetwomodeloutputs(model, model2, dataloaders[\"val\"], device)\n",
    "\n",
    "    # order 1e-3 is okay, 1e-2 is still okay.\n",
    "    print(f\"model checking averaged difference {avgdiff} for case {case}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "approved-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training is super slow and bad for both cases\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = config[\"lr\"])\n",
    "\n",
    "lr_sc = optim.lr_scheduler.StepLR(optimizer, step_size = config[\"scheduler_stepsize\"], gamma = config[\"scheduler_factor\"]) # Decay LR by a factor of 0.3 every X epochs\n",
    "\n",
    "best_all, trainlosses, testlosses, testperfs = traineval2_model_nocv(\n",
    "        dataloaders[\"train\"], dataloaders[\"val\"], model2, loss_func, optimizer, lr_sc, num_epochs=config[\"maxnumepochs\"], device=device, numcl=config[\"numcl\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-thriller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
